{"ast":null,"code":"function ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    if (enumerableOnly) symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    });\n    keys.push.apply(keys, symbols);\n  }\n\n  return keys;\n}\n\nfunction _objectSpread(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        _defineProperty(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n\n  return target;\n}\n\nfunction _defineProperty(obj, key, value) {\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n\n  return obj;\n} // `SpeechRecognition` is an API used on the browser so we can safely disable\n// the `window` check.\n\n/* eslint-disable no-restricted-globals */\n\n/* global SpeechRecognition SpeechRecognitionEvent */\n\n\nvar createVoiceSearchHelper = function createVoiceSearchHelper(_ref) {\n  var searchAsYouSpeak = _ref.searchAsYouSpeak,\n      language = _ref.language,\n      onQueryChange = _ref.onQueryChange,\n      onStateChange = _ref.onStateChange;\n  var SpeechRecognitionAPI = window.webkitSpeechRecognition || window.SpeechRecognition;\n\n  var getDefaultState = function getDefaultState(status) {\n    return {\n      status: status,\n      transcript: '',\n      isSpeechFinal: false,\n      errorCode: undefined\n    };\n  };\n\n  var state = getDefaultState('initial');\n  var recognition;\n\n  var isBrowserSupported = function isBrowserSupported() {\n    return Boolean(SpeechRecognitionAPI);\n  };\n\n  var isListening = function isListening() {\n    return state.status === 'askingPermission' || state.status === 'waiting' || state.status === 'recognizing';\n  };\n\n  var setState = function setState() {\n    var newState = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    state = _objectSpread(_objectSpread({}, state), newState);\n    onStateChange();\n  };\n\n  var getState = function getState() {\n    return state;\n  };\n\n  var resetState = function resetState() {\n    var status = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'initial';\n    setState(getDefaultState(status));\n  };\n\n  var onStart = function onStart() {\n    setState({\n      status: 'waiting'\n    });\n  };\n\n  var onError = function onError(event) {\n    setState({\n      status: 'error',\n      errorCode: event.error\n    });\n  };\n\n  var onResult = function onResult(event) {\n    setState({\n      status: 'recognizing',\n      transcript: event.results[0] && event.results[0][0] && event.results[0][0].transcript || '',\n      isSpeechFinal: event.results[0] && event.results[0].isFinal\n    });\n\n    if (searchAsYouSpeak && state.transcript) {\n      onQueryChange(state.transcript);\n    }\n  };\n\n  var onEnd = function onEnd() {\n    if (!state.errorCode && state.transcript && !searchAsYouSpeak) {\n      onQueryChange(state.transcript);\n    }\n\n    if (state.status !== 'error') {\n      setState({\n        status: 'finished'\n      });\n    }\n  };\n\n  var startListening = function startListening() {\n    recognition = new SpeechRecognitionAPI();\n\n    if (!recognition) {\n      return;\n    }\n\n    resetState('askingPermission');\n    recognition.interimResults = true;\n\n    if (language) {\n      recognition.lang = language;\n    }\n\n    recognition.addEventListener('start', onStart);\n    recognition.addEventListener('error', onError);\n    recognition.addEventListener('result', onResult);\n    recognition.addEventListener('end', onEnd);\n    recognition.start();\n  };\n\n  var dispose = function dispose() {\n    if (!recognition) {\n      return;\n    }\n\n    recognition.stop();\n    recognition.removeEventListener('start', onStart);\n    recognition.removeEventListener('error', onError);\n    recognition.removeEventListener('result', onResult);\n    recognition.removeEventListener('end', onEnd);\n    recognition = undefined;\n  };\n\n  var stopListening = function stopListening() {\n    dispose(); // Because `dispose` removes event listeners, `end` listener is not called.\n    // So we're setting the `status` as `finished` here.\n    // If we don't do it, it will be still `waiting` or `recognizing`.\n\n    resetState('finished');\n  };\n\n  return {\n    getState: getState,\n    isBrowserSupported: isBrowserSupported,\n    isListening: isListening,\n    startListening: startListening,\n    stopListening: stopListening,\n    dispose: dispose\n  };\n};\n\nexport default createVoiceSearchHelper;","map":null,"metadata":{},"sourceType":"module"}